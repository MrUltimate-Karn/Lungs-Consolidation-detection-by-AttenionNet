{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\n\ndataset_path = os.listdir('../input/b7-dataset/MINOR PROJECT')\n\nprint (dataset_path)\n\nprint(\"Types of classes labels found: \", len(dataset_path))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-29T08:11:32.902145Z","iopub.execute_input":"2022-04-29T08:11:32.902458Z","iopub.status.idle":"2022-04-29T08:11:37.205073Z","shell.execute_reply.started":"2022-04-29T08:11:32.902431Z","shell.execute_reply":"2022-04-29T08:11:37.204321Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class_labels = []\n\nfor item in dataset_path:\n    all_classes = os.listdir('../input/b7-dataset/MINOR PROJECT' + '/' +item)\n    for room in all_classes:\n        class_labels.append((item, str('dataset_path' + '/' +item) + '/' + room))\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:11:37.206676Z","iopub.execute_input":"2022-04-29T08:11:37.207323Z","iopub.status.idle":"2022-04-29T08:11:37.686047Z","shell.execute_reply.started":"2022-04-29T08:11:37.207284Z","shell.execute_reply":"2022-04-29T08:11:37.685273Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data=class_labels, columns=['Labels', 'image'])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:11:37.689325Z","iopub.execute_input":"2022-04-29T08:11:37.690030Z","iopub.status.idle":"2022-04-29T08:11:37.698158Z","shell.execute_reply.started":"2022-04-29T08:11:37.689988Z","shell.execute_reply":"2022-04-29T08:11:37.697284Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(\"Total number of images in the dataset: \", len(df))\n\nlabel_count = df['Labels'].value_counts()\nprint(label_count)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:11:37.699377Z","iopub.execute_input":"2022-04-29T08:11:37.699776Z","iopub.status.idle":"2022-04-29T08:11:37.716237Z","shell.execute_reply.started":"2022-04-29T08:11:37.699696Z","shell.execute_reply":"2022-04-29T08:11:37.715466Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import cv2\npath = '../input/b7-dataset/MINOR PROJECT'\ndataset_path = os.listdir('../input/b7-dataset/MINOR PROJECT')\n\nim_size = 300\n\nimages = []\nlabels = []\n\nfor i in dataset_path:\n    data_path = path+'/' + str(i)  \n    filenames = [i for i in os.listdir(data_path) ]\n   \n    for f in filenames:\n        img = cv2.imread(data_path + '/' + f)\n        img = cv2.resize(img, (im_size, im_size))\n#         print(img.shape)\n        \n        images.append(img)\n        labels.append(i)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:11:39.907633Z","iopub.execute_input":"2022-04-29T08:11:39.908281Z","iopub.status.idle":"2022-04-29T08:12:23.637161Z","shell.execute_reply.started":"2022-04-29T08:11:39.908243Z","shell.execute_reply":"2022-04-29T08:12:23.636376Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"images = np.array(images)\n# print(images[0])\nimages = images.astype('float32') / 255.0\n# print(images[0])\nimages.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:12:23.638820Z","iopub.execute_input":"2022-04-29T08:12:23.639071Z","iopub.status.idle":"2022-04-29T08:12:24.531239Z","shell.execute_reply.started":"2022-04-29T08:12:23.639038Z","shell.execute_reply":"2022-04-29T08:12:24.530530Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder , OneHotEncoder\ny=df['Labels'].values\n\n\ny_labelencoder = LabelEncoder ()\ny = y_labelencoder.fit_transform (y)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:12:24.532574Z","iopub.execute_input":"2022-04-29T08:12:24.532839Z","iopub.status.idle":"2022-04-29T08:12:25.086590Z","shell.execute_reply.started":"2022-04-29T08:12:24.532805Z","shell.execute_reply":"2022-04-29T08:12:25.085889Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"y=y.reshape(-1,1)\n\nfrom sklearn.compose import ColumnTransformer\nct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\nY = ct.fit_transform(y) #.toarray()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:12:25.103405Z","iopub.execute_input":"2022-04-29T08:12:25.103674Z","iopub.status.idle":"2022-04-29T08:12:25.111471Z","shell.execute_reply.started":"2022-04-29T08:12:25.103624Z","shell.execute_reply":"2022-04-29T08:12:25.110818Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB3\n\nNUM_CLASSES = 2\nIMG_SIZE = 300\nsize = (IMG_SIZE, IMG_SIZE)\n\n\ninputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n\n\n\noutputs = EfficientNetB3(include_top=True, weights=None, classes=NUM_CLASSES)(inputs)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:12:25.113034Z","iopub.execute_input":"2022-04-29T08:12:25.113368Z","iopub.status.idle":"2022-04-29T08:12:30.749121Z","shell.execute_reply.started":"2022-04-29T08:12:25.113325Z","shell.execute_reply":"2022-04-29T08:12:30.748399Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\n\n\nimages, Y = shuffle(images, Y, random_state=1)\n\ntrain_x, test_x, train_y, test_y = train_test_split(images, Y, test_size=0.25, random_state=415)\n\n#inpect the shape of the training and testing.\nprint(train_x.shape)\nprint(train_y.shape)\nprint(test_x.shape)\nprint(test_y.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:12:30.750263Z","iopub.execute_input":"2022-04-29T08:12:30.750519Z","iopub.status.idle":"2022-04-29T08:12:32.132203Z","shell.execute_reply.started":"2022-04-29T08:12:30.750486Z","shell.execute_reply":"2022-04-29T08:12:32.131343Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(inputs, outputs)\n\nmodel.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"] )\n\nmodel.summary()\n\nhist = model.fit(train_x, train_y, epochs=30, verbose=2)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:12:32.136123Z","iopub.execute_input":"2022-04-29T08:12:32.138280Z","iopub.status.idle":"2022-04-29T08:30:04.921272Z","shell.execute_reply.started":"2022-04-29T08:12:32.138239Z","shell.execute_reply":"2022-04-29T08:30:04.920455Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(hist.history[\"accuracy\"])\n# plt.plot(hist.history[\"val_accuracy\"])\nplt.title(\"model accuracy\")\nplt.ylabel(\"accuracy\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"validation\"], loc=\"upper left\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:04.922925Z","iopub.execute_input":"2022-04-29T08:30:04.923190Z","iopub.status.idle":"2022-04-29T08:30:05.145799Z","shell.execute_reply.started":"2022-04-29T08:30:04.923155Z","shell.execute_reply":"2022-04-29T08:30:05.145121Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"preds = model.evaluate(test_x, test_y)\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:05.148649Z","iopub.execute_input":"2022-04-29T08:30:05.149064Z","iopub.status.idle":"2022-04-29T08:30:10.818293Z","shell.execute_reply.started":"2022-04-29T08:30:05.149027Z","shell.execute_reply":"2022-04-29T08:30:10.817237Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from matplotlib.pyplot import imread\nfrom matplotlib.pyplot import imshow\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.imagenet_utils import decode_predictions\nfrom tensorflow.keras.applications.imagenet_utils import preprocess_input\n\n\nimg_path = '../input/b7-dataset/MINOR PROJECT/Consolidation/00000242_000.png'\n\n\n\nimg = cv2.imread(img_path)\nimg = cv2.resize(img, (300, 300))\n\nx = np.expand_dims(img, axis=0)\nx = preprocess_input(x)\n\nprint('Input image shape:', x.shape)\n\nmy_image = imread(img_path)\nimshow(my_image)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:10.819773Z","iopub.execute_input":"2022-04-29T08:30:10.820075Z","iopub.status.idle":"2022-04-29T08:30:11.198322Z","shell.execute_reply.started":"2022-04-29T08:30:10.820035Z","shell.execute_reply":"2022-04-29T08:30:11.197621Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"preds=model.predict(x)\npreds = preds.reshape(1,-1)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:11.199265Z","iopub.execute_input":"2022-04-29T08:30:11.199580Z","iopub.status.idle":"2022-04-29T08:30:13.246263Z","shell.execute_reply.started":"2022-04-29T08:30:11.199543Z","shell.execute_reply":"2022-04-29T08:30:13.245476Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:13.247739Z","iopub.execute_input":"2022-04-29T08:30:13.248013Z","iopub.status.idle":"2022-04-29T08:30:13.254259Z","shell.execute_reply.started":"2022-04-29T08:30:13.247976Z","shell.execute_reply":"2022-04-29T08:30:13.253530Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class ChannelAttention(tf.keras.layers.Layer):\n      def _init_(self, filters, ratio):\n        super(ChannelAttention, self)._init_()\n        self.filters = filters\n        self.ratio = ratio\n\n        def build(self, input_shape):\n            self.shared_layer_one = tf.keras.layers.Dense(self.filters//self.ratio,\n                             activation='relu', kernel_initializer='he_normal', \n                              use_bias=True, \n                              bias_initializer='zeros')\n            self.shared_layer_two = tf.keras.layers.Dense(self.filters,\n                             kernel_initializer='he_normal',\n                             use_bias=True,\n                             bias_initializer='zeros')\n\n        def call(self, inputs):\n            # AvgPool\n            avg_pool = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n            \n\n            avg_pool = self.shared_layer_one(avg_pool)\n            avg_pool = self.shared_layer_two(avg_pool)\n\n\n\n            attention = tf.keras.layers.Add()([avg_pool,max_pool])\n            attention = tf.keras.layers.Activation('sigmoid')(attention)\n            \n            return tf.keras.layers.Multiply()([inputs, attention])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:13.255685Z","iopub.execute_input":"2022-04-29T08:30:13.256117Z","iopub.status.idle":"2022-04-29T08:30:13.266665Z","shell.execute_reply.started":"2022-04-29T08:30:13.256079Z","shell.execute_reply":"2022-04-29T08:30:13.265995Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class SpatialAttention(tf.keras.layers.Layer):\n      def _init_(self, kernel_size):\n        super(SpatialAttention, self)._init_()\n        self.kernel_size = kernel_size\n        \n        def build(self, input_shape):\n            self.conv2d = tf.keras.layers.Conv2D(filters = 1,\n                    kernel_size=self.kernel_size,\n                    strides=1,\n                    padding='same',\n                    activation='sigmoid',\n                    kernel_initializer='he_normal',\n                    use_bias=False)\n\n        def call(self, inputs):\n            \n            # AvgPool\n            avg_pool = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x, axis=3, keepdims=True))(inputs)\n            \n\n            attention = tf.keras.layers.Concatenate(axis=3)([avg_pool, max_pool])\n\n            attention = self.conv2d(attention)\n\n\n            return tf.keras.layers.multiply([inputs, attention])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:13.267781Z","iopub.execute_input":"2022-04-29T08:30:13.268371Z","iopub.status.idle":"2022-04-29T08:30:13.277696Z","shell.execute_reply.started":"2022-04-29T08:30:13.268334Z","shell.execute_reply":"2022-04-29T08:30:13.276979Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"efnb3 = EfficientNetB3(weights=None, include_top=False, input_shape=train_x.shape[1:], classes=2)\nsimple_cnn_with_attention = tf.keras.models.Sequential()\nsimple_cnn_with_attention.add(efnb3)\nsimple_cnn_with_attention.add(tf.keras.layers.Conv2D(32, 3, input_shape= train_x.shape[1:], activation='elu', padding='same'))\nsimple_cnn_with_attention.add( tf.keras.layers.BatchNormalization())\nsimple_cnn_with_attention.add( tf.keras.layers.Conv2D(32, 3, padding='same', activation='elu'))\nsimple_cnn_with_attention.add( tf.keras.layers.BatchNormalization())\nsimple_cnn_with_attention.add( ChannelAttention())\nsimple_cnn_with_attention.add(SpatialAttention())\nsimple_cnn_with_attention.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nsimple_cnn_with_attention.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='elu'))\nsimple_cnn_with_attention.add(tf.keras.layers.BatchNormalization())\nsimple_cnn_with_attention.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='elu'))\nsimple_cnn_with_attention.add(tf.keras.layers.BatchNormalization())\nsimple_cnn_with_attention.add(ChannelAttention())\nsimple_cnn_with_attention.add(SpatialAttention())\nsimple_cnn_with_attention.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\nsimple_cnn_with_attention.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='elu'),)\n\nsimple_cnn_with_attention.add(tf.keras.layers.BatchNormalization())\n\nsimple_cnn_with_attention.add( tf.keras.layers.Conv2D(128, 3, padding='same', activation='elu'))\n\nsimple_cnn_with_attention.add(ChannelAttention())\n\nsimple_cnn_with_attention.add(SpatialAttention())\n\nsimple_cnn_with_attention.add(tf.keras.layers.GlobalAveragePooling2D())\n\nsimple_cnn_with_attention.add(tf.keras.layers.Dense(2, activation='softmax' ))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:13.279159Z","iopub.execute_input":"2022-04-29T08:30:13.279798Z","iopub.status.idle":"2022-04-29T08:30:16.461711Z","shell.execute_reply.started":"2022-04-29T08:30:13.279761Z","shell.execute_reply":"2022-04-29T08:30:16.460963Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:16.463140Z","iopub.execute_input":"2022-04-29T08:30:16.463391Z","iopub.status.idle":"2022-04-29T08:30:16.499425Z","shell.execute_reply.started":"2022-04-29T08:30:16.463358Z","shell.execute_reply":"2022-04-29T08:30:16.498775Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"simple_cnn_with_attention.compile(\n    loss='categorical_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(0.001),\n    metrics=['accuracy'],\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:16.500737Z","iopub.execute_input":"2022-04-29T08:30:16.500975Z","iopub.status.idle":"2022-04-29T08:30:16.516010Z","shell.execute_reply.started":"2022-04-29T08:30:16.500943Z","shell.execute_reply":"2022-04-29T08:30:16.515067Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"history = simple_cnn_with_attention.fit(train_x, train_y, epochs=30)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:30:16.517463Z","iopub.execute_input":"2022-04-29T08:30:16.517996Z","iopub.status.idle":"2022-04-29T08:48:54.537468Z","shell.execute_reply.started":"2022-04-29T08:30:16.517970Z","shell.execute_reply":"2022-04-29T08:48:54.536714Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(f\"Test accuracy: {simple_cnn_with_attention.evaluate(test_x,test_y)[1]}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:48:54.538921Z","iopub.execute_input":"2022-04-29T08:48:54.540779Z","iopub.status.idle":"2022-04-29T08:49:00.053035Z","shell.execute_reply.started":"2022-04-29T08:48:54.540746Z","shell.execute_reply":"2022-04-29T08:49:00.052252Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"accuracy\"])\n# plt.plot(hist.history[\"val_accuracy\"])\nplt.title(\"model accuracy\")\nplt.ylabel(\"accuracy\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"validation\"], loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T08:49:00.054641Z","iopub.execute_input":"2022-04-29T08:49:00.054987Z","iopub.status.idle":"2022-04-29T08:49:00.248291Z","shell.execute_reply.started":"2022-04-29T08:49:00.054946Z","shell.execute_reply":"2022-04-29T08:49:00.247526Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"y_pred = history.predict()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nmatrix_confusion = confusion_matrix(y_test, y_pred)","metadata":{},"execution_count":null,"outputs":[]}]}